{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%alias package {__import__('sys').executable} -m pip install --quiet --upgrade %l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rU_Mxyr64tA9"
   },
   "outputs": [],
   "source": [
    "session_storage = 'downloads'\n",
    "\n",
    "import os\n",
    "os.makedirs(session_storage, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mmMz4GWV4tA9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "%package fsspec\n",
    "\n",
    "import fsspec\n",
    "\n",
    "fs_dataset = fsspec.filesystem(\n",
    "    'simplecache', \n",
    "    target_protocol='https', \n",
    "    cache_storage=session_storage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wSh2EXOe4tA9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-gpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.3.0 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 22.11.23 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.23.5 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.4.0 which is incompatible.\r\n",
      "scipy 1.7.0 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.5 which is incompatible.\u001b[0m\r\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-gpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.3.0 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 22.11.23 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.22.4 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.4.0 which is incompatible.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "%package numpy pandas \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''\n",
    "%package swifter\n",
    "import swifter\n",
    "swifter.set_defaults(\n",
    "    npartitions=None,\n",
    "    dask_thres=1,\n",
    "    scheduler='processes',\n",
    "    progress_bar=True,\n",
    "    progress_bar_desc=None,\n",
    "    allow_dask_on_strings=True,\n",
    "    force_parallel=False\n",
    ")\n",
    "'''\n",
    "\n",
    "%package scikit-learn\n",
    "import sklearn as skl\n",
    "import sklearn.base\n",
    "import sklearn.compose\n",
    "#import sklearn.ensemble\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.svm\n",
    "\n",
    "'''\n",
    "%package scikit-learn-intelex\n",
    "import sklearnex\n",
    "sklearnex.patch_sklearn()\n",
    "'''\n",
    "\n",
    "%package xgboost\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 11:45:22.447094: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 11:45:23.314012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib/:/opt/conda/lib/\n",
      "2022-12-01 11:45:23.314088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib/:/opt/conda/lib/\n",
      "2022-12-01 11:45:23.314097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%package tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "%package spacy spacy-transformers\n",
    "\n",
    "import spacy\n",
    "import spacy_transformers\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "spacy.cli.download('en_core_web_lg', False, False, '--quiet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "%package scikeras\n",
    "\n",
    "import scikeras as skeras\n",
    "import scikeras.wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "df_scripts = pd.read_pickle('./dataset.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>script_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>[\\r\\n\\r\\n\\r\\n\\r\\n                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man Who Knew Too Much, The Script</td>\n",
       "      <td>[                   THE MAN WHO KNEW TOO MUCH\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crow Salvation, The Script</td>\n",
       "      <td>[\\r\\n\\r\\n      \"THE CROW: SALVATION\" -- by Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die Hard 2 Script</td>\n",
       "      <td>[\\r\\n\\r\\n \\r\\n                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Game 6 Script</td>\n",
       "      <td>[           \\r\\n          \\r\\n          \\r\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Cooler, The Script</td>\n",
       "      <td>[\\r\\n\\r\\n\\r\\n                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>Hitchcock Script</td>\n",
       "      <td>[\\r\\n\\r\\n\\r\\n\\r\\n                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>Breaking Away Script</td>\n",
       "      <td>[\\r\\n\\r\\n \\r\\n                            \"BAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>Batman Returns Script</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>[\\r\\n\\r\\n                          \\r\\n       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            script_name  \\\n",
       "0             American Milkshake Script   \n",
       "1     Man Who Knew Too Much, The Script   \n",
       "2            Crow Salvation, The Script   \n",
       "3                     Die Hard 2 Script   \n",
       "4                         Game 6 Script   \n",
       "...                                 ...   \n",
       "1204                 Cooler, The Script   \n",
       "1205                   Hitchcock Script   \n",
       "1206               Breaking Away Script   \n",
       "1207              Batman Returns Script   \n",
       "1208           Sandlot Kids, The Script   \n",
       "\n",
       "                                            script_text  \n",
       "0     [\\r\\n\\r\\n\\r\\n\\r\\n                             ...  \n",
       "1     [                   THE MAN WHO KNEW TOO MUCH\\...  \n",
       "2     [\\r\\n\\r\\n      \"THE CROW: SALVATION\" -- by Chi...  \n",
       "3     [\\r\\n\\r\\n \\r\\n                                ...  \n",
       "4     [           \\r\\n          \\r\\n          \\r\\n  ...  \n",
       "...                                                 ...  \n",
       "1204  [\\r\\n\\r\\n\\r\\n                                 ...  \n",
       "1205  [\\r\\n\\r\\n\\r\\n\\r\\n                             ...  \n",
       "1206  [\\r\\n\\r\\n \\r\\n                            \"BAM...  \n",
       "1207                                                 []  \n",
       "1208  [\\r\\n\\r\\n                          \\r\\n       ...  \n",
       "\n",
       "[1209 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts = df_scripts.astype({\n",
    "    'script_name': 'category'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts = df_scripts.explode('script_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>script_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n                             A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man Who Knew Too Much, The Script</td>\n",
       "      <td>THE MAN WHO KNEW TOO MUCH\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crow Salvation, The Script</td>\n",
       "      <td>\\r\\n\\r\\n      \"THE CROW: SALVATION\" -- by Chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die Hard 2 Script</td>\n",
       "      <td>\\r\\n\\r\\n \\r\\n                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Game 6 Script</td>\n",
       "      <td>\\r\\n          \\r\\n          \\r\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>Ninja Assassin Script</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n                         NINJA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Cooler, The Script</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>Hitchcock Script</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n                              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>Breaking Away Script</td>\n",
       "      <td>\\r\\n\\r\\n \\r\\n                            \"BAMB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>\\r\\n\\r\\n                          \\r\\n        ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            script_name  \\\n",
       "0             American Milkshake Script   \n",
       "1     Man Who Knew Too Much, The Script   \n",
       "2            Crow Salvation, The Script   \n",
       "3                     Die Hard 2 Script   \n",
       "4                         Game 6 Script   \n",
       "...                                 ...   \n",
       "1203              Ninja Assassin Script   \n",
       "1204                 Cooler, The Script   \n",
       "1205                   Hitchcock Script   \n",
       "1206               Breaking Away Script   \n",
       "1208           Sandlot Kids, The Script   \n",
       "\n",
       "                                            script_text  \n",
       "0     \\r\\n\\r\\n\\r\\n\\r\\n                             A...  \n",
       "1                        THE MAN WHO KNEW TOO MUCH\\r...  \n",
       "2     \\r\\n\\r\\n      \"THE CROW: SALVATION\" -- by Chip...  \n",
       "3     \\r\\n\\r\\n \\r\\n                                 ...  \n",
       "4                \\r\\n          \\r\\n          \\r\\n   ...  \n",
       "...                                                 ...  \n",
       "1203  \\r\\n\\r\\n\\r\\n\\r\\n                         NINJA...  \n",
       "1204  \\r\\n\\r\\n\\r\\n                                  ...  \n",
       "1205  \\r\\n\\r\\n\\r\\n\\r\\n                              ...  \n",
       "1206  \\r\\n\\r\\n \\r\\n                            \"BAMB...  \n",
       "1208  \\r\\n\\r\\n                          \\r\\n        ...  \n",
       "\n",
       "[1177 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataset_scripts.iloc[0]['script_text'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "GOAL extract the following features from texts:\n",
    "\n",
    "Feature engineering TODO list: \n",
    "- location: Named Entity Recognition\n",
    "- character: Named Entity Recognition\n",
    "    see https://keras.io/examples/nlp/ner_transformers/\n",
    "    see https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54\n",
    "- convo: ??\n",
    "\n",
    "sentence embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_normalize_eol(s, eol=os.linesep):\n",
    "    return str.join(eol, str.splitlines(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "%package joblib\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import joblib\n",
    "\n",
    "class ParagraphExtractor(skl.base.TransformerMixin):\n",
    "    def __init__(self,\n",
    "        eol=os.linesep, #'\\r\\n' #os.linesep\n",
    "        eol_freq_min=2,\n",
    "        n_jobs=1\n",
    "    ):\n",
    "        self.eol = eol\n",
    "        self.eol_freq_min = eol_freq_min\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self._pattern = re.compile(\n",
    "            fr'(?:{self.eol}\\s*?){{{self.eol_freq_min},}}'\n",
    "        )\n",
    "\n",
    "    def fit(self, _X, _y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, _y=None):\n",
    "        def _impl_single(s):\n",
    "            nonlocal self\n",
    "            return re.split(\n",
    "                self._pattern,\n",
    "                str_normalize_eol(s, eol=self.eol)\n",
    "            )\n",
    "\n",
    "        return joblib.Parallel(n_jobs=self.n_jobs)(\n",
    "            joblib.delayed(_impl_single)(s)\n",
    "                for s in X\n",
    "        )\n",
    "\n",
    "        \n",
    "df_scripts['script_paragraphs'] = ParagraphExtractor(n_jobs=-1).fit_transform(\n",
    "    df_scripts['script_text']#.iloc[:100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts_para = (\n",
    "    df_scripts[['script_name', 'script_paragraphs']]\n",
    "        .explode('script_paragraphs', ignore_index=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts_para['script_paragraphs'] = (\n",
    "    df_scripts_para['script_paragraphs'].str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts_para = df_scripts_para[\n",
    "    # non-empty strings\n",
    "    df_scripts_para['script_paragraphs'].astype(bool)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>script_paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>AMERICAN MILKSHAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>Written by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>David Andalman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>Co-writer, Mariko Munro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>9/28/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999877</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>makeshit baseball diamond - a sandlot... circa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999878</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>A baseball. A baseball with a familiar smudge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999879</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>END TITLES.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999880</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>FADE OUT.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999881</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>THE END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1905869 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       script_name  \\\n",
       "1        American Milkshake Script   \n",
       "2        American Milkshake Script   \n",
       "3        American Milkshake Script   \n",
       "4        American Milkshake Script   \n",
       "6        American Milkshake Script   \n",
       "...                            ...   \n",
       "1999877   Sandlot Kids, The Script   \n",
       "1999878   Sandlot Kids, The Script   \n",
       "1999879   Sandlot Kids, The Script   \n",
       "1999880   Sandlot Kids, The Script   \n",
       "1999881   Sandlot Kids, The Script   \n",
       "\n",
       "                                         script_paragraphs  \n",
       "1                                       AMERICAN MILKSHAKE  \n",
       "2                                               Written by  \n",
       "3                                           David Andalman  \n",
       "4                                  Co-writer, Mariko Munro  \n",
       "6                                                9/28/2011  \n",
       "...                                                    ...  \n",
       "1999877  makeshit baseball diamond - a sandlot... circa...  \n",
       "1999878     A baseball. A baseball with a familiar smudge.  \n",
       "1999879                                        END TITLES.  \n",
       "1999880                                          FADE OUT.  \n",
       "1999881                                            THE END  \n",
       "\n",
       "[1905869 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scripts_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO rm\n",
    "#df_scripts['script_paragraphs'].iloc[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (LSTM RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasTextVectorizer(skl.base.TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.base = keras.layers.TextVectorization(\n",
    "            *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def fit(self, X, _y=None):\n",
    "        self.base.adapt(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, _y=None):\n",
    "        return self.base(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyTextVectorizer(KerasTextVectorizer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        nlp = spacy.load('en_core_web_lg')\n",
    "        super().__init__(\n",
    "            *args, \n",
    "            vocabulary=list(nlp.vocab.strings),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def fit(self, _X, _y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KerasTextClassifier(*args, **kwargs):\n",
    "    class _class(skeras.wrappers.KerasClassifier):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "            self.n_features_in_ = None\n",
    "            self._user_target_encoder = (\n",
    "                skl.preprocessing.OneHotEncoder(\n",
    "                    sparse=False\n",
    "                )\n",
    "            )\n",
    "\n",
    "        @property\n",
    "        def target_encoder(self):\n",
    "            return self._user_target_encoder\n",
    "\n",
    "    _inst = None\n",
    "\n",
    "    def _build_model(optimizer='adam'):\n",
    "        nonlocal _inst\n",
    "\n",
    "        n_features = _inst.n_features_in_\n",
    "        n_classes = np.size(_inst._user_target_encoder.categories_)\n",
    "\n",
    "        input_dim = n_features\n",
    "        output_dim = n_classes\n",
    "\n",
    "        # https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Embedding(\n",
    "                input_dim=input_dim,\n",
    "                output_dim=128,\n",
    "                mask_zero=True\n",
    "            ),\n",
    "\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32, kernel_size=3, \n",
    "                padding='same', \n",
    "                activation='relu'\n",
    "            ),\n",
    "            keras.layers.MaxPooling1D(pool_size=10),\n",
    "            keras.layers.Dropout(.1),\n",
    "\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "\n",
    "            keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "            keras.layers.Dense(\n",
    "                output_dim,\n",
    "                activation='softmax'\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy', \n",
    "            optimizer=optimizer, \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    _inst = _class(\n",
    "        _build_model, \n",
    "        *args, **kwargs\n",
    "    )\n",
    "    return _inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictor (Vocab From Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model_nn(X, y):\n",
    "    encoder = KerasTextVectorizer(\n",
    "        max_tokens=None,\n",
    "        standardize='lower_and_strip_punctuation',\n",
    "        split='whitespace',\n",
    "        #ngrams=(1, 2),\n",
    "        output_mode='int', # TODO tf_idf\n",
    "        #sparse=True,\n",
    "    )\n",
    "\n",
    "    X = encoder.fit_transform(X)\n",
    "\n",
    "    clf = KerasTextClassifier(\n",
    "        callbacks=[\n",
    "            #keras.callbacks.EarlyStopping(\n",
    "            #    monitor='loss', \n",
    "            #    patience=3, \n",
    "            #    min_delta=0.0001\n",
    "            #),\n",
    "            #keras.callbacks.LambdaCallback(\n",
    "            #    on_train_end=lambda logs: print(logs)\n",
    "            #)\n",
    "        ]\n",
    "    )\n",
    "    clf.initialize(X, y)\n",
    "    \n",
    "    model = skl.model_selection.GridSearchCV(\n",
    "        clf,\n",
    "        param_grid={\n",
    "            'epochs': [5],\n",
    "            'batch_size': [1024]\n",
    "        },\n",
    "        cv=skl.model_selection.RepeatedStratifiedKFold(\n",
    "            n_splits=3, n_repeats=1\n",
    "        ),\n",
    "        #cv=skl.model_selection.KFold(\n",
    "        #    n_splits=5, shuffle=True\n",
    "        #),\n",
    "        #n_jobs=-1,\n",
    "        verbose=3\n",
    "    )\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 11:46:45.330487: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 11:46:45.968846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3 MB memory:  -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:3d:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py:684: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "[CV 1/3] END ...........batch_size=1024, epochs=5;, score=nan total time=   1.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 11:46:58.528093: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 106.0KiB (rounded to 108544)requested by op Mul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-01 11:46:58.528177: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-01 11:46:58.528208: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 31, Chunks in use: 31. 7.8KiB allocated for chunks. 7.8KiB in use in bin. 408B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528232: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.5KiB client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528254: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 9, Chunks in use: 9. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528276: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528296: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528318: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 10.0KiB allocated for chunks. 10.0KiB in use in bin. 9.9KiB client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528340: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 19.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528364: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 8, Chunks in use: 5. 331.0KiB allocated for chunks. 176.0KiB in use in bin. 176.0KiB client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528386: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 17, Chunks in use: 16. 1.25MiB allocated for chunks. 1.19MiB in use in bin. 1.13MiB client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528410: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 6, Chunks in use: 6. 768.0KiB allocated for chunks. 768.0KiB in use in bin. 729.0KiB client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528433: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 3, Chunks in use: 3. 1.00MiB allocated for chunks. 1.00MiB in use in bin. 771.8KiB client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528452: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528472: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528492: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528511: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528531: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528550: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528570: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528589: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528609: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528630: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:46:58.528652: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 106.0KiB was 64.0KiB, Chunk State: \n",
      "2022-12-01 11:46:58.528686: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 64.0KiB | Requested Size: 64.0KiB | in_use: 0 | bin_num: 8, prev:   Size: 64.0KiB | Requested Size: 64.0KiB | in_use: 1 | bin_num: -1, next:   Size: 128.0KiB | Requested Size: 128.0KiB | in_use: 1 | bin_num: -1\n",
      "2022-12-01 11:46:58.528724: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 3538944\n",
      "2022-12-01 11:46:58.528747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800000 of size 1280 next 1\n",
      "2022-12-01 11:46:58.528769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800500 of size 256 next 2\n",
      "2022-12-01 11:46:58.528787: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800600 of size 256 next 3\n",
      "2022-12-01 11:46:58.528803: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800700 of size 256 next 4\n",
      "2022-12-01 11:46:58.528820: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800800 of size 256 next 5\n",
      "2022-12-01 11:46:58.528837: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800900 of size 256 next 10\n",
      "2022-12-01 11:46:58.528853: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800a00 of size 256 next 7\n",
      "2022-12-01 11:46:58.528870: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800b00 of size 10240 next 8\n",
      "2022-12-01 11:46:58.528887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618803300 of size 256 next 9\n",
      "2022-12-01 11:46:58.528904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618803400 of size 256 next 12\n",
      "2022-12-01 11:46:58.528921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618803500 of size 32768 next 23\n",
      "2022-12-01 11:46:58.528939: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b500 of size 256 next 20\n",
      "2022-12-01 11:46:58.528955: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b600 of size 256 next 21\n",
      "2022-12-01 11:46:58.528972: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b700 of size 256 next 19\n",
      "2022-12-01 11:46:58.528988: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b800 of size 256 next 22\n",
      "2022-12-01 11:46:58.529005: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b900 of size 256 next 24\n",
      "2022-12-01 11:46:58.529021: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880ba00 of size 256 next 33\n",
      "2022-12-01 11:46:58.529037: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880bb00 of size 256 next 25\n",
      "2022-12-01 11:46:58.529055: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880bc00 of size 1024 next 26\n",
      "2022-12-01 11:46:58.529071: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f361880c000 of size 63488 next 17\n",
      "2022-12-01 11:46:58.529088: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361881b800 of size 49152 next 18\n",
      "2022-12-01 11:46:58.529105: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827800 of size 256 next 13\n",
      "2022-12-01 11:46:58.529121: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827900 of size 256 next 14\n",
      "2022-12-01 11:46:58.529138: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827a00 of size 256 next 6\n",
      "2022-12-01 11:46:58.529154: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827b00 of size 256 next 11\n",
      "2022-12-01 11:46:58.529171: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827c00 of size 68096 next 15\n",
      "2022-12-01 11:46:58.529189: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618838600 of size 108544 next 16\n",
      "2022-12-01 11:46:58.529207: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618852e00 of size 1024 next 31\n",
      "2022-12-01 11:46:58.529224: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853200 of size 512 next 36\n",
      "2022-12-01 11:46:58.529241: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853400 of size 1024 next 37\n",
      "2022-12-01 11:46:58.529258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853800 of size 1024 next 41\n",
      "2022-12-01 11:46:58.529274: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853c00 of size 256 next 42\n",
      "2022-12-01 11:46:58.529291: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853d00 of size 256 next 44\n",
      "2022-12-01 11:46:58.529308: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853e00 of size 768 next 45\n",
      "2022-12-01 11:46:58.529325: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854100 of size 256 next 46\n",
      "2022-12-01 11:46:58.529342: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854200 of size 256 next 49\n",
      "2022-12-01 11:46:58.529358: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854300 of size 256 next 50\n",
      "2022-12-01 11:46:58.529375: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854400 of size 256 next 53\n",
      "2022-12-01 11:46:58.529393: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854500 of size 512 next 65\n",
      "2022-12-01 11:46:58.529409: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854700 of size 256 next 76\n",
      "2022-12-01 11:46:58.529426: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854800 of size 256 next 55\n",
      "2022-12-01 11:46:58.529442: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854900 of size 1024 next 61\n",
      "2022-12-01 11:46:58.529459: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854d00 of size 1024 next 59\n",
      "2022-12-01 11:46:58.529475: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855100 of size 1024 next 51\n",
      "2022-12-01 11:46:58.529492: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855500 of size 1024 next 72\n",
      "2022-12-01 11:46:58.529509: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855900 of size 768 next 68\n",
      "2022-12-01 11:46:58.529525: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855c00 of size 256 next 77\n",
      "2022-12-01 11:46:58.529542: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855d00 of size 256 next 56\n",
      "2022-12-01 11:46:58.529558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855e00 of size 256 next 80\n",
      "2022-12-01 11:46:58.529574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855f00 of size 256 next 78\n",
      "2022-12-01 11:46:58.529591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f3618856000 of size 19968 next 28\n",
      "2022-12-01 11:46:58.529607: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361885ae00 of size 32768 next 27\n",
      "2022-12-01 11:46:58.529624: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f3618862e00 of size 32768 next 57\n",
      "2022-12-01 11:46:58.529640: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361886ae00 of size 32768 next 29\n",
      "2022-12-01 11:46:58.529657: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618872e00 of size 65536 next 30\n",
      "2022-12-01 11:46:58.529674: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618882e00 of size 65536 next 32\n",
      "2022-12-01 11:46:58.529690: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618892e00 of size 65536 next 43\n",
      "2022-12-01 11:46:58.529720: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36188a2e00 of size 131072 next 35\n",
      "2022-12-01 11:46:58.529737: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36188c2e00 of size 131072 next 34\n",
      "2022-12-01 11:46:58.529753: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36188e2e00 of size 65536 next 40\n",
      "2022-12-01 11:46:58.529769: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36188f2e00 of size 65536 next 39\n",
      "2022-12-01 11:46:58.529786: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618902e00 of size 131072 next 38\n",
      "2022-12-01 11:46:58.529802: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618922e00 of size 32768 next 62\n",
      "2022-12-01 11:46:58.529819: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f361892ae00 of size 62464 next 48\n",
      "2022-12-01 11:46:58.529836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361893a200 of size 95232 next 47\n",
      "2022-12-01 11:46:58.529854: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618951600 of size 339200 next 52\n",
      "2022-12-01 11:46:58.529871: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36189a4300 of size 291328 next 63\n",
      "2022-12-01 11:46:58.529887: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36189eb500 of size 65536 next 60\n",
      "2022-12-01 11:46:58.529904: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36189fb500 of size 86016 next 58\n",
      "2022-12-01 11:46:58.529921: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a10500 of size 108544 next 54\n",
      "2022-12-01 11:46:58.529937: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a2ad00 of size 65536 next 64\n",
      "2022-12-01 11:46:58.529954: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a3ad00 of size 65536 next 73\n",
      "2022-12-01 11:46:58.529970: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a4ad00 of size 131072 next 67\n",
      "2022-12-01 11:46:58.529987: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a6ad00 of size 131072 next 66\n",
      "2022-12-01 11:46:58.530003: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a8ad00 of size 65536 next 71\n",
      "2022-12-01 11:46:58.530020: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f3618a9ad00 of size 65536 next 70\n",
      "2022-12-01 11:46:58.530036: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618aaad00 of size 131072 next 69\n",
      "2022-12-01 11:46:58.530053: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618acad00 of size 95232 next 75\n",
      "2022-12-01 11:46:58.530069: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618ae2100 of size 95232 next 74\n",
      "2022-12-01 11:46:58.530087: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618af9500 of size 420608 next 18446744073709551615\n",
      "2022-12-01 11:46:58.530103: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2022-12-01 11:46:58.530124: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 31 Chunks of size 256 totalling 7.8KiB\n",
      "2022-12-01 11:46:58.530144: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2022-12-01 11:46:58.530162: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 768 totalling 1.5KiB\n",
      "2022-12-01 11:46:58.530180: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 1024 totalling 8.0KiB\n",
      "2022-12-01 11:46:58.530198: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-01 11:46:58.530217: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10240 totalling 10.0KiB\n",
      "2022-12-01 11:46:58.530236: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 32768 totalling 128.0KiB\n",
      "2022-12-01 11:46:58.530255: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 49152 totalling 48.0KiB\n",
      "2022-12-01 11:46:58.530273: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 65536 totalling 576.0KiB\n",
      "2022-12-01 11:46:58.530292: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 68096 totalling 66.5KiB\n",
      "2022-12-01 11:46:58.530310: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 86016 totalling 84.0KiB\n",
      "2022-12-01 11:46:58.530329: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 95232 totalling 279.0KiB\n",
      "2022-12-01 11:46:58.530348: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 108544 totalling 212.0KiB\n",
      "2022-12-01 11:46:58.530366: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 131072 totalling 768.0KiB\n",
      "2022-12-01 11:46:58.530385: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 291328 totalling 284.5KiB\n",
      "2022-12-01 11:46:58.530404: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 339200 totalling 331.2KiB\n",
      "2022-12-01 11:46:58.530423: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 420608 totalling 410.8KiB\n",
      "2022-12-01 11:46:58.530441: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 3.14MiB\n",
      "2022-12-01 11:46:58.530460: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 3538944 memory_limit_: 3538944 available bytes: 0 curr_region_allocation_bytes_: 7077888\n",
      "2022-12-01 11:46:58.530486: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                         3538944\n",
      "InUse:                         3294720\n",
      "MaxInUse:                      3294720\n",
      "NumAllocs:                         337\n",
      "MaxAllocSize:                   420608\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-01 11:46:58.530518: W tensorflow/tsl/framework/bfc_allocator.cc:492] **_********************************_******************************************_****************xxxxx\n",
      "2022-12-01 11:46:58.530573: W tensorflow/core/framework/op_kernel.cc:1818] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...........batch_size=1024, epochs=5;, score=nan total time=  10.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 11:47:08.579683: W tensorflow/tsl/framework/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 106.0KiB (rounded to 108544)requested by op Mul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-01 11:47:08.579778: I tensorflow/tsl/framework/bfc_allocator.cc:1034] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-01 11:47:08.579812: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (256): \tTotal Chunks: 31, Chunks in use: 31. 7.8KiB allocated for chunks. 7.8KiB in use in bin. 408B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.579838: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (512): \tTotal Chunks: 4, Chunks in use: 4. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.5KiB client-requested in use in bin.\n",
      "2022-12-01 11:47:08.579862: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1024): \tTotal Chunks: 9, Chunks in use: 9. 9.2KiB allocated for chunks. 9.2KiB in use in bin. 9.0KiB client-requested in use in bin.\n",
      "2022-12-01 11:47:08.579886: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.579908: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.579933: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8192): \tTotal Chunks: 1, Chunks in use: 1. 10.0KiB allocated for chunks. 10.0KiB in use in bin. 9.9KiB client-requested in use in bin.\n",
      "2022-12-01 11:47:08.579956: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16384): \tTotal Chunks: 1, Chunks in use: 0. 19.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.579983: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (32768): \tTotal Chunks: 8, Chunks in use: 5. 331.0KiB allocated for chunks. 176.0KiB in use in bin. 176.0KiB client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580007: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (65536): \tTotal Chunks: 17, Chunks in use: 16. 1.25MiB allocated for chunks. 1.19MiB in use in bin. 1.13MiB client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580032: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (131072): \tTotal Chunks: 6, Chunks in use: 6. 768.0KiB allocated for chunks. 768.0KiB in use in bin. 727.3KiB client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580057: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (262144): \tTotal Chunks: 3, Chunks in use: 3. 1.00MiB allocated for chunks. 1.00MiB in use in bin. 773.5KiB client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580078: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580099: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580120: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580141: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580162: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580183: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580204: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580225: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580246: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580269: I tensorflow/tsl/framework/bfc_allocator.cc:1041] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-01 11:47:08.580292: I tensorflow/tsl/framework/bfc_allocator.cc:1057] Bin for 106.0KiB was 64.0KiB, Chunk State: \n",
      "2022-12-01 11:47:08.580329: I tensorflow/tsl/framework/bfc_allocator.cc:1063]   Size: 64.0KiB | Requested Size: 64.0KiB | in_use: 0 | bin_num: 8, prev:   Size: 64.0KiB | Requested Size: 64.0KiB | in_use: 1 | bin_num: -1, next:   Size: 128.0KiB | Requested Size: 128.0KiB | in_use: 1 | bin_num: -1\n",
      "2022-12-01 11:47:08.580348: I tensorflow/tsl/framework/bfc_allocator.cc:1070] Next region of size 3538944\n",
      "2022-12-01 11:47:08.580372: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800000 of size 1280 next 1\n",
      "2022-12-01 11:47:08.580395: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800500 of size 256 next 2\n",
      "2022-12-01 11:47:08.580413: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800600 of size 256 next 3\n",
      "2022-12-01 11:47:08.580431: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800700 of size 256 next 4\n",
      "2022-12-01 11:47:08.580448: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800800 of size 256 next 5\n",
      "2022-12-01 11:47:08.580466: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800900 of size 256 next 10\n",
      "2022-12-01 11:47:08.580483: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800a00 of size 256 next 7\n",
      "2022-12-01 11:47:08.580501: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618800b00 of size 10240 next 8\n",
      "2022-12-01 11:47:08.580519: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618803300 of size 256 next 9\n",
      "2022-12-01 11:47:08.580537: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618803400 of size 256 next 12\n",
      "2022-12-01 11:47:08.580555: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618803500 of size 32768 next 23\n",
      "2022-12-01 11:47:08.580574: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b500 of size 256 next 20\n",
      "2022-12-01 11:47:08.580591: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b600 of size 256 next 21\n",
      "2022-12-01 11:47:08.580609: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b700 of size 256 next 19\n",
      "2022-12-01 11:47:08.580627: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b800 of size 256 next 22\n",
      "2022-12-01 11:47:08.580645: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880b900 of size 256 next 24\n",
      "2022-12-01 11:47:08.580662: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880ba00 of size 256 next 33\n",
      "2022-12-01 11:47:08.580679: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880bb00 of size 256 next 25\n",
      "2022-12-01 11:47:08.580710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361880bc00 of size 1024 next 26\n",
      "2022-12-01 11:47:08.580728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f361880c000 of size 63488 next 17\n",
      "2022-12-01 11:47:08.580747: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361881b800 of size 49152 next 18\n",
      "2022-12-01 11:47:08.580765: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827800 of size 256 next 13\n",
      "2022-12-01 11:47:08.580783: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827900 of size 256 next 14\n",
      "2022-12-01 11:47:08.580800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827a00 of size 256 next 6\n",
      "2022-12-01 11:47:08.580818: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827b00 of size 256 next 11\n",
      "2022-12-01 11:47:08.580836: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618827c00 of size 68096 next 15\n",
      "2022-12-01 11:47:08.580855: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618838600 of size 108544 next 16\n",
      "2022-12-01 11:47:08.580874: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618852e00 of size 1024 next 31\n",
      "2022-12-01 11:47:08.580892: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853200 of size 512 next 36\n",
      "2022-12-01 11:47:08.580910: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853400 of size 1024 next 37\n",
      "2022-12-01 11:47:08.580927: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853800 of size 1024 next 41\n",
      "2022-12-01 11:47:08.580945: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853c00 of size 256 next 42\n",
      "2022-12-01 11:47:08.580962: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853d00 of size 256 next 44\n",
      "2022-12-01 11:47:08.580980: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618853e00 of size 768 next 45\n",
      "2022-12-01 11:47:08.580998: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854100 of size 256 next 46\n",
      "2022-12-01 11:47:08.581016: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854200 of size 256 next 49\n",
      "2022-12-01 11:47:08.581033: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854300 of size 256 next 50\n",
      "2022-12-01 11:47:08.581050: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854400 of size 256 next 53\n",
      "2022-12-01 11:47:08.581068: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854500 of size 512 next 65\n",
      "2022-12-01 11:47:08.581086: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854700 of size 256 next 76\n",
      "2022-12-01 11:47:08.581102: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854800 of size 256 next 55\n",
      "2022-12-01 11:47:08.581120: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854900 of size 1024 next 61\n",
      "2022-12-01 11:47:08.581138: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618854d00 of size 1024 next 59\n",
      "2022-12-01 11:47:08.581155: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855100 of size 1024 next 51\n",
      "2022-12-01 11:47:08.581173: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855500 of size 1024 next 72\n",
      "2022-12-01 11:47:08.581190: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855900 of size 768 next 68\n",
      "2022-12-01 11:47:08.581208: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855c00 of size 256 next 77\n",
      "2022-12-01 11:47:08.581225: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855d00 of size 256 next 56\n",
      "2022-12-01 11:47:08.581242: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855e00 of size 256 next 79\n",
      "2022-12-01 11:47:08.581258: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618855f00 of size 256 next 80\n",
      "2022-12-01 11:47:08.581275: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f3618856000 of size 19968 next 28\n",
      "2022-12-01 11:47:08.581293: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361885ae00 of size 32768 next 27\n",
      "2022-12-01 11:47:08.581310: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f3618862e00 of size 32768 next 57\n",
      "2022-12-01 11:47:08.581328: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361886ae00 of size 32768 next 29\n",
      "2022-12-01 11:47:08.581347: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618872e00 of size 65536 next 30\n",
      "2022-12-01 11:47:08.581365: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618882e00 of size 65536 next 32\n",
      "2022-12-01 11:47:08.581382: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618892e00 of size 65536 next 43\n",
      "2022-12-01 11:47:08.581400: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36188a2e00 of size 131072 next 35\n",
      "2022-12-01 11:47:08.581417: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36188c2e00 of size 131072 next 34\n",
      "2022-12-01 11:47:08.581435: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36188e2e00 of size 65536 next 40\n",
      "2022-12-01 11:47:08.581451: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36188f2e00 of size 65536 next 39\n",
      "2022-12-01 11:47:08.581469: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618902e00 of size 131072 next 38\n",
      "2022-12-01 11:47:08.581487: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618922e00 of size 32768 next 62\n",
      "2022-12-01 11:47:08.581504: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f361892ae00 of size 62464 next 48\n",
      "2022-12-01 11:47:08.581521: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f361893a200 of size 95232 next 47\n",
      "2022-12-01 11:47:08.581540: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618951600 of size 339200 next 52\n",
      "2022-12-01 11:47:08.581558: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36189a4300 of size 291328 next 63\n",
      "2022-12-01 11:47:08.581576: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36189eb500 of size 65536 next 60\n",
      "2022-12-01 11:47:08.581594: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f36189fb500 of size 86016 next 58\n",
      "2022-12-01 11:47:08.581614: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a10500 of size 108544 next 54\n",
      "2022-12-01 11:47:08.581631: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a2ad00 of size 65536 next 64\n",
      "2022-12-01 11:47:08.581648: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a3ad00 of size 65536 next 73\n",
      "2022-12-01 11:47:08.581666: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a4ad00 of size 131072 next 67\n",
      "2022-12-01 11:47:08.581684: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a6ad00 of size 131072 next 66\n",
      "2022-12-01 11:47:08.581710: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618a8ad00 of size 65536 next 71\n",
      "2022-12-01 11:47:08.581728: I tensorflow/tsl/framework/bfc_allocator.cc:1090] Free  at 7f3618a9ad00 of size 65536 next 70\n",
      "2022-12-01 11:47:08.581746: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618aaad00 of size 131072 next 69\n",
      "2022-12-01 11:47:08.581764: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618acad00 of size 95232 next 75\n",
      "2022-12-01 11:47:08.581781: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618ae2100 of size 95232 next 74\n",
      "2022-12-01 11:47:08.581800: I tensorflow/tsl/framework/bfc_allocator.cc:1090] InUse at 7f3618af9500 of size 420608 next 18446744073709551615\n",
      "2022-12-01 11:47:08.581817: I tensorflow/tsl/framework/bfc_allocator.cc:1095]      Summary of in-use Chunks by size: \n",
      "2022-12-01 11:47:08.581839: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 31 Chunks of size 256 totalling 7.8KiB\n",
      "2022-12-01 11:47:08.581859: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2022-12-01 11:47:08.581878: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 768 totalling 1.5KiB\n",
      "2022-12-01 11:47:08.581896: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 8 Chunks of size 1024 totalling 8.0KiB\n",
      "2022-12-01 11:47:08.581916: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-01 11:47:08.581936: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 10240 totalling 10.0KiB\n",
      "2022-12-01 11:47:08.581957: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 4 Chunks of size 32768 totalling 128.0KiB\n",
      "2022-12-01 11:47:08.581977: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 49152 totalling 48.0KiB\n",
      "2022-12-01 11:47:08.581997: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 9 Chunks of size 65536 totalling 576.0KiB\n",
      "2022-12-01 11:47:08.582016: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 68096 totalling 66.5KiB\n",
      "2022-12-01 11:47:08.582036: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 86016 totalling 84.0KiB\n",
      "2022-12-01 11:47:08.582056: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 3 Chunks of size 95232 totalling 279.0KiB\n",
      "2022-12-01 11:47:08.582076: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 2 Chunks of size 108544 totalling 212.0KiB\n",
      "2022-12-01 11:47:08.582097: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 6 Chunks of size 131072 totalling 768.0KiB\n",
      "2022-12-01 11:47:08.582116: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 291328 totalling 284.5KiB\n",
      "2022-12-01 11:47:08.582136: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 339200 totalling 331.2KiB\n",
      "2022-12-01 11:47:08.582156: I tensorflow/tsl/framework/bfc_allocator.cc:1098] 1 Chunks of size 420608 totalling 410.8KiB\n",
      "2022-12-01 11:47:08.582176: I tensorflow/tsl/framework/bfc_allocator.cc:1102] Sum Total of in-use chunks: 3.14MiB\n",
      "2022-12-01 11:47:08.582196: I tensorflow/tsl/framework/bfc_allocator.cc:1104] total_region_allocated_bytes_: 3538944 memory_limit_: 3538944 available bytes: 0 curr_region_allocation_bytes_: 7077888\n",
      "2022-12-01 11:47:08.582222: I tensorflow/tsl/framework/bfc_allocator.cc:1110] Stats: \n",
      "Limit:                         3538944\n",
      "InUse:                         3294720\n",
      "MaxInUse:                      3294720\n",
      "NumAllocs:                         359\n",
      "MaxAllocSize:                   420608\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-01 11:47:08.582256: W tensorflow/tsl/framework/bfc_allocator.cc:492] **_********************************_******************************************_****************xxxxx\n",
      "2022-12-01 11:47:08.582288: W tensorflow/core/framework/op_kernel.cc:1818] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...........batch_size=1024, epochs=5;, score=nan total time=  10.0s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1494, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_filep1y699t0.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 129) and (None, 186) are incompatible\n\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1494, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 918, in _fit\n    X, y = self._initialize(X, y)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 855, in _initialize\n    self.model_ = self._build_keras_model()\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 431, in _build_keras_model\n    model = final_build_fn(**build_params)\n  File \"/tmp/ipykernel_124189/835238596.py\", line 29, in _build_model\n    model = keras.Sequential([\n  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/trackable/base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/conda/lib/python3.9/site-packages/keras/backend.py\", line 2100, in random_uniform\n    return tf.random.stateless_uniform(\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_124189/1705131490.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_scripts_para_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_scripts_para\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model_nn = _model_nn(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_scripts_para_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'script_paragraphs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_scripts_para_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'script_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_124189/2472576876.py\u001b[0m in \u001b[0;36m_model_nn\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    850\u001b[0m                     )\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1494, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_filep1y699t0.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.9/site-packages/keras/losses.py\", line 2004, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.9/site-packages/keras/backend.py\", line 5532, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 129) and (None, 186) are incompatible\n\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 1494, in fit\n    super().fit(X=X, y=y, sample_weight=sample_weight, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 918, in _fit\n    X, y = self._initialize(X, y)\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 855, in _initialize\n    self.model_ = self._build_keras_model()\n  File \"/opt/conda/lib/python3.9/site-packages/scikeras/wrappers.py\", line 431, in _build_keras_model\n    model = final_build_fn(**build_params)\n  File \"/tmp/ipykernel_124189/835238596.py\", line 29, in _build_model\n    model = keras.Sequential([\n  File \"/opt/conda/lib/python3.9/site-packages/tensorflow/python/trackable/base.py\", line 205, in _method_wrapper\n    result = method(self, *args, **kwargs)\n  File \"/opt/conda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/conda/lib/python3.9/site-packages/keras/backend.py\", line 2100, in random_uniform\n    return tf.random.stateless_uniform(\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "df_scripts_para_ = df_scripts_para.sample(200)\n",
    "model_nn = _model_nn(\n",
    "    X=df_scripts_para_['script_paragraphs'],\n",
    "    y=df_scripts_para_[['script_name']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
