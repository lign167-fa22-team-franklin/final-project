{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%alias package {__import__('sys').executable} -m pip install --quiet --upgrade %l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rU_Mxyr64tA9"
   },
   "outputs": [],
   "source": [
    "session_storage = 'downloads'\n",
    "\n",
    "import os\n",
    "os.makedirs(session_storage, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mmMz4GWV4tA9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "%package fsspec\n",
    "\n",
    "import fsspec\n",
    "\n",
    "fs_dataset = fsspec.filesystem(\n",
    "    'simplecache', \n",
    "    target_protocol='https', \n",
    "    cache_storage=session_storage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wSh2EXOe4tA9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-gpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.3.0 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 22.11.23 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.23.5 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.4.0 which is incompatible.\r\n",
      "scipy 1.7.0 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.23.5 which is incompatible.\u001b[0m\r\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-gpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.3.0 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires flatbuffers~=1.12.0, but you have flatbuffers 22.11.23 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.22.4 which is incompatible.\r\n",
      "tensorflow-gpu 2.6.0 requires typing-extensions~=3.7.4, but you have typing-extensions 4.4.0 which is incompatible.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "%package numpy pandas \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "'''\n",
    "%package swifter\n",
    "import swifter\n",
    "swifter.set_defaults(\n",
    "    npartitions=None,\n",
    "    dask_thres=1,\n",
    "    scheduler='processes',\n",
    "    progress_bar=True,\n",
    "    progress_bar_desc=None,\n",
    "    allow_dask_on_strings=True,\n",
    "    force_parallel=False\n",
    ")\n",
    "'''\n",
    "\n",
    "%package scikit-learn\n",
    "import sklearn as skl\n",
    "import sklearn.base\n",
    "import sklearn.compose\n",
    "#import sklearn.ensemble\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.svm\n",
    "\n",
    "'''\n",
    "%package scikit-learn-intelex\n",
    "import sklearnex\n",
    "sklearnex.patch_sklearn()\n",
    "'''\n",
    "\n",
    "%package xgboost\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 10:09:29.405531: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 10:09:30.343094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib/:/opt/conda/lib/\n",
      "2022-12-01 10:09:30.343172: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/opt/conda/lib/:/opt/conda/lib/\n",
      "2022-12-01 10:09:30.343181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%package tensorflow\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "%package spacy spacy-transformers\n",
    "\n",
    "import spacy\n",
    "import spacy_transformers\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "spacy.cli.download('en_core_web_lg', False, False, '--quiet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "%package scikeras\n",
    "\n",
    "import scikeras as skeras\n",
    "import scikeras.wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "df_scripts = pd.read_pickle('./dataset.pkl', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>script_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>[\\r\\n\\r\\n\\r\\n\\r\\n                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man Who Knew Too Much, The Script</td>\n",
       "      <td>[                   THE MAN WHO KNEW TOO MUCH\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crow Salvation, The Script</td>\n",
       "      <td>[\\r\\n\\r\\n      \"THE CROW: SALVATION\" -- by Chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die Hard 2 Script</td>\n",
       "      <td>[\\r\\n\\r\\n \\r\\n                                ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Game 6 Script</td>\n",
       "      <td>[           \\r\\n          \\r\\n          \\r\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Cooler, The Script</td>\n",
       "      <td>[\\r\\n\\r\\n\\r\\n                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>Hitchcock Script</td>\n",
       "      <td>[\\r\\n\\r\\n\\r\\n\\r\\n                             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>Breaking Away Script</td>\n",
       "      <td>[\\r\\n\\r\\n \\r\\n                            \"BAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>Batman Returns Script</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>[\\r\\n\\r\\n                          \\r\\n       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            script_name  \\\n",
       "0             American Milkshake Script   \n",
       "1     Man Who Knew Too Much, The Script   \n",
       "2            Crow Salvation, The Script   \n",
       "3                     Die Hard 2 Script   \n",
       "4                         Game 6 Script   \n",
       "...                                 ...   \n",
       "1204                 Cooler, The Script   \n",
       "1205                   Hitchcock Script   \n",
       "1206               Breaking Away Script   \n",
       "1207              Batman Returns Script   \n",
       "1208           Sandlot Kids, The Script   \n",
       "\n",
       "                                            script_text  \n",
       "0     [\\r\\n\\r\\n\\r\\n\\r\\n                             ...  \n",
       "1     [                   THE MAN WHO KNEW TOO MUCH\\...  \n",
       "2     [\\r\\n\\r\\n      \"THE CROW: SALVATION\" -- by Chi...  \n",
       "3     [\\r\\n\\r\\n \\r\\n                                ...  \n",
       "4     [           \\r\\n          \\r\\n          \\r\\n  ...  \n",
       "...                                                 ...  \n",
       "1204  [\\r\\n\\r\\n\\r\\n                                 ...  \n",
       "1205  [\\r\\n\\r\\n\\r\\n\\r\\n                             ...  \n",
       "1206  [\\r\\n\\r\\n \\r\\n                            \"BAM...  \n",
       "1207                                                 []  \n",
       "1208  [\\r\\n\\r\\n                          \\r\\n       ...  \n",
       "\n",
       "[1209 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts = df_scripts.astype({\n",
    "    'script_name': 'category'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts = df_scripts.explode('script_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scripts.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_name</th>\n",
       "      <th>script_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Milkshake Script</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n                             A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Man Who Knew Too Much, The Script</td>\n",
       "      <td>THE MAN WHO KNEW TOO MUCH\\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crow Salvation, The Script</td>\n",
       "      <td>\\r\\n\\r\\n      \"THE CROW: SALVATION\" -- by Chip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Die Hard 2 Script</td>\n",
       "      <td>\\r\\n\\r\\n \\r\\n                                 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Game 6 Script</td>\n",
       "      <td>\\r\\n          \\r\\n          \\r\\n   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>Ninja Assassin Script</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n                         NINJA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Cooler, The Script</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n                                  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>Hitchcock Script</td>\n",
       "      <td>\\r\\n\\r\\n\\r\\n\\r\\n                              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>Breaking Away Script</td>\n",
       "      <td>\\r\\n\\r\\n \\r\\n                            \"BAMB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>Sandlot Kids, The Script</td>\n",
       "      <td>\\r\\n\\r\\n                          \\r\\n        ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1177 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            script_name  \\\n",
       "0             American Milkshake Script   \n",
       "1     Man Who Knew Too Much, The Script   \n",
       "2            Crow Salvation, The Script   \n",
       "3                     Die Hard 2 Script   \n",
       "4                         Game 6 Script   \n",
       "...                                 ...   \n",
       "1203              Ninja Assassin Script   \n",
       "1204                 Cooler, The Script   \n",
       "1205                   Hitchcock Script   \n",
       "1206               Breaking Away Script   \n",
       "1208           Sandlot Kids, The Script   \n",
       "\n",
       "                                            script_text  \n",
       "0     \\r\\n\\r\\n\\r\\n\\r\\n                             A...  \n",
       "1                        THE MAN WHO KNEW TOO MUCH\\r...  \n",
       "2     \\r\\n\\r\\n      \"THE CROW: SALVATION\" -- by Chip...  \n",
       "3     \\r\\n\\r\\n \\r\\n                                 ...  \n",
       "4                \\r\\n          \\r\\n          \\r\\n   ...  \n",
       "...                                                 ...  \n",
       "1203  \\r\\n\\r\\n\\r\\n\\r\\n                         NINJA...  \n",
       "1204  \\r\\n\\r\\n\\r\\n                                  ...  \n",
       "1205  \\r\\n\\r\\n\\r\\n\\r\\n                              ...  \n",
       "1206  \\r\\n\\r\\n \\r\\n                            \"BAMB...  \n",
       "1208  \\r\\n\\r\\n                          \\r\\n        ...  \n",
       "\n",
       "[1177 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "GOAL extract the following features from texts:\n",
    "\n",
    "Feature engineering TODO list: \n",
    "- location: Named Entity Recognition\n",
    "- character: Named Entity Recognition\n",
    "    see https://keras.io/examples/nlp/ner_transformers/\n",
    "    see https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54\n",
    "- convo: ??\n",
    "\n",
    "sentence embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataset_scripts.iloc[0]['script_text'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n\\r\\n\\r\\n\\r\\n                             AMERICAN MILKSHAKE\\r\\n                         \\r\\n\\r\\n\\r\\n                                 Written by\\r\\n\\r\\n                               David Andalman\\r\\n                         \\r\\n                          Co-writer, Mariko Munro\\r\\n                         \\r\\n                         \\r\\n                         \\r\\n                                                             9/28/2011\\r\\n                         \\r\\n                         \\r\\n                         \\r\\n                        \\r\\n\\r\\n          INT. OLD FASHIONED STAGE\\r\\n                         \\r\\n          Circa 1900.\\r\\n                         \\r\\n          A white man in a top hat introduces the final act of a black\\r\\n          face performance.\\r\\n                         \\r\\n                              TOP HAT MAN\\r\\n                    In the spirit of true minstrelsy,\\r\\n                    you have again shown that laughter\\r\\n                    is the wine of life.\\r\\n                         \\r\\n          Some'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scripts.iloc[0]['script_text'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '\\r\\n',\n",
       " '                             AMERICAN MILKSHAKE',\n",
       " '\\r\\n',\n",
       " '                                 Written by',\n",
       " '\\r\\n',\n",
       " '                               David Andalman',\n",
       " '\\r\\n',\n",
       " '                          Co-writer, Mariko Munro',\n",
       " '\\r\\n',\n",
       " '                         ',\n",
       " '\\r\\n',\n",
       " '                                                             9/28/2011',\n",
       " '\\r\\n',\n",
       " '                         ',\n",
       " '\\r\\n',\n",
       " '                        ',\n",
       " '\\r\\n',\n",
       " '          INT. OLD FASHIONED STAGE',\n",
       " '\\r\\n',\n",
       " '          Circa 1900.',\n",
       " '\\r\\n',\n",
       " '          A white man in a top hat introduces the final act of a black\\r\\n          face performance.',\n",
       " '\\r\\n',\n",
       " '                              TOP HAT MAN\\r\\n                    In the spirit of true minstrelsy,\\r\\n                    you have again shown that laughter\\r\\n                    is the wine of life.',\n",
       " '\\r\\n',\n",
       " '          Some']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(\n",
    "'(?:(\\r\\n)\\s*?){2,}',\n",
    "    df_scripts.iloc[0]['script_text'][:1000]\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a c d']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.splitlines('a c d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_normalize_eol(s, eol=os.linesep):\n",
    "    return str.join(eol, str.splitlines(s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\\\n'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.escape(os.linesep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eol == '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n                             AMERICAN MILKSHAKE\\n                         \\n\\n\\n                                 Written by\\n\\n                               David Andalman\\n                         \\n                          Co-writer, Mariko Munro\\n                         \\n                         \\n                         \\n                                                             9/28/2011\\n                         \\n                         \\n                         \\n                        \\n\\n          INT. OLD FASHIONED STAGE\\n                         \\n          Circa 1900.\\n                         \\n          A white man in a top hat introduces the final act of a black\\n          face performance.\\n                         \\n                              TOP HAT MAN\\n                    In the spirit of true minstrelsy,\\n                    you have again shown that laughter\\n                    is the wine of life.\\n                         \\n          Some'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_normalize_eol(\n",
    "        df_scripts.iloc[0]['script_text'][:1000],\n",
    "        eol=eol\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "%package joblib\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import joblib\n",
    "\n",
    "class ParagraphExtractor(skl.base.TransformerMixin):\n",
    "    def __init__(self,\n",
    "        eol=os.linesep, #'\\r\\n' #os.linesep\n",
    "        eol_freq_min=2,\n",
    "        n_jobs=1\n",
    "    ):\n",
    "        self.eol = eol\n",
    "        self.eol_freq_min = eol_freq_min\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        self._pattern = re.compile(\n",
    "            fr'(?:{self.eol}\\s*?){{{self.eol_freq_min},}}'\n",
    "        )\n",
    "\n",
    "    def fit(self, _X, _y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, _y=None):\n",
    "        def _impl_single(s):\n",
    "            nonlocal self\n",
    "            return re.split(\n",
    "                self._pattern,\n",
    "                str_normalize_eol(s, eol=self.eol)\n",
    "            )\n",
    "\n",
    "        return joblib.Parallel(n_jobs=self.n_jobs)(\n",
    "            joblib.delayed(_impl_single)(s)\n",
    "                for s in X\n",
    "        )\n",
    "\n",
    "        \n",
    "df_scripts['script_paragraphs'] = ParagraphExtractor(n_jobs=-1).fit_transform(\n",
    "    df_scripts['script_text'].iloc[:100]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "unknown extension ?> at position 4 (line 1, column 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30415/3151376005.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# TODO NOTE match at least two line breaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp_newline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(?>\\r\\n|\\n|\\x0b|\\f|\\r|\\x85|\\x2028|\\x2029)'\u001b[0m \u001b[0;31m#'(\\r\\n?|\\n)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mfr'(?:{p_newline}+\\s*){{2,}}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_scripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'script_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(str, flags, state)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_VERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;31m# the VERBOSE flag was switched on inside the pattern.  to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    444\u001b[0m                            not nested and not items))\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    832\u001b[0m             sub_verbose = ((verbose or (add_flags & SRE_FLAG_VERBOSE)) and\n\u001b[1;32m    833\u001b[0m                            not (del_flags & SRE_FLAG_VERBOSE))\n\u001b[0;32m--> 834\u001b[0;31m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parse_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_verbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnested\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\")\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m                 raise source.error(\"missing ), unterminated subpattern\",\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36m_parse_sub\u001b[0;34m(source, state, verbose, nested)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         itemsappend(_parse(source, state, verbose, nested + 1,\n\u001b[0m\u001b[1;32m    444\u001b[0m                            not nested and not items))\n\u001b[1;32m    445\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msourcematch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"|\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/sre_parse.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[1;32m    821\u001b[0m                     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m                     raise source.error(\"unknown extension ?\" + char,\n\u001b[0m\u001b[1;32m    824\u001b[0m                                        len(char) + 1)\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: unknown extension ?> at position 4 (line 1, column 5)"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# TODO NOTE match at least two line breaks\n",
    "p_newline = '(?>\\r\\n|\\n|\\x0b|\\f|\\r|\\x85|\\x2028|\\x2029)' #'(\\r\\n?|\\n)'\n",
    "p = re.compile(fr'(?:{p_newline}+\\s*){{2,}}')\n",
    "\n",
    "re.split(p, df_scripts.iloc[0]['script_text'])\n",
    "\n",
    "re.split(p, df_scripts.iloc[0]['script_text'][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (LSTM RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasTextVectorizer(skl.base.TransformerMixin):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.base = keras.layers.TextVectorization(\n",
    "            *args, **kwargs\n",
    "        )\n",
    "\n",
    "    def fit(self, X, _y=None):\n",
    "        self.base.adapt(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, _y=None):\n",
    "        return self.base(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyTextVectorizer(KerasTextVectorizer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        nlp = spacy.load('en_core_web_lg')\n",
    "        super().__init__(\n",
    "            *args, \n",
    "            vocabulary=list(nlp.vocab.strings),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def fit(self, _X, _y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KerasTextClassifier(*args, **kwargs):\n",
    "    class _class(skeras.wrappers.KerasClassifier):\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "\n",
    "            self.n_features_in_ = None\n",
    "            self._user_target_encoder = (\n",
    "                skl.preprocessing.OneHotEncoder(\n",
    "                    sparse=False\n",
    "                )\n",
    "            )\n",
    "\n",
    "        @property\n",
    "        def target_encoder(self):\n",
    "            return self._user_target_encoder\n",
    "\n",
    "    _inst = None\n",
    "\n",
    "    def _build_model(optimizer='adam'):\n",
    "        nonlocal _inst\n",
    "\n",
    "        n_features = _inst.n_features_in_\n",
    "        n_classes = np.size(_inst._user_target_encoder.categories_)\n",
    "\n",
    "        input_dim = n_features\n",
    "        output_dim = n_classes\n",
    "\n",
    "        # https://www.tensorflow.org/tutorials/keras/text_classification\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Embedding(\n",
    "                input_dim=input_dim,\n",
    "                output_dim=128,\n",
    "                mask_zero=True\n",
    "            ),\n",
    "\n",
    "            keras.layers.Conv1D(\n",
    "                filters=32, kernel_size=3, \n",
    "                padding='same', \n",
    "                activation='relu'\n",
    "            ),\n",
    "            keras.layers.MaxPooling1D(pool_size=10),\n",
    "            keras.layers.Dropout(.1),\n",
    "\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
    "            keras.layers.Bidirectional(keras.layers.LSTM(64)),\n",
    "\n",
    "            keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "            keras.layers.Dense(\n",
    "                output_dim,\n",
    "                activation='softmax'\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy', \n",
    "            optimizer=optimizer, \n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    _inst = _class(\n",
    "        _build_model, \n",
    "        *args, **kwargs\n",
    "    )\n",
    "    return _inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictor (Vocab From Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _model_nn(X, y):\n",
    "    encoder = KerasTextVectorizer(\n",
    "        max_tokens=None,\n",
    "        standardize='lower_and_strip_punctuation',\n",
    "        split='whitespace',\n",
    "        #ngrams=(1, 2),\n",
    "        output_mode='int', # TODO tf_idf\n",
    "        #sparse=True,\n",
    "    )\n",
    "\n",
    "    X = encoder.fit_transform(X)\n",
    "\n",
    "    clf = KerasTextClassifier(\n",
    "        callbacks=[\n",
    "            #keras.callbacks.EarlyStopping(\n",
    "            #    monitor='loss', \n",
    "            #    patience=3, \n",
    "            #    min_delta=0.0001\n",
    "            #),\n",
    "            #keras.callbacks.LambdaCallback(\n",
    "            #    on_train_end=lambda logs: print(logs)\n",
    "            #)\n",
    "        ]\n",
    "    )\n",
    "    clf.initialize(X, y)\n",
    "    \n",
    "    model = skl.model_selection.GridSearchCV(\n",
    "        clf,\n",
    "        param_grid={\n",
    "            'epochs': [5],\n",
    "            'batch_size': [1024]\n",
    "        },\n",
    "        cv=skl.model_selection.RepeatedStratifiedKFold(\n",
    "            n_splits=3, n_repeats=1\n",
    "        ),\n",
    "        #cv=skl.model_selection.KFold(\n",
    "        #    n_splits=5, shuffle=True\n",
    "        #),\n",
    "        #n_jobs=-1,\n",
    "        verbose=3\n",
    "    )\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_splits=3 cannot be greater than the number of members in each class.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30415/4233699879.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf_scripts_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_scripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m model_nn = _model_nn(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_scripts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'script_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_scripts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'script_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30415/3684360485.py\u001b[0m in \u001b[0;36m_model_nn\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m     )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    832\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0mfit_and_score_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                     )\n\u001b[0;32m--> 834\u001b[0;31m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0m\u001b[1;32m    835\u001b[0m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    338\u001b[0m             )\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mmin_groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0my_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    680\u001b[0m                 \u001b[0;34m\"n_splits=%d cannot be greater than the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;34m\" number of members in each class.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_splits=3 cannot be greater than the number of members in each class."
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "df_scripts_ = df_scripts.sample(200)\n",
    "model_nn = _model_nn(\n",
    "    X=df_scripts_['script_text'],\n",
    "    y=df_scripts_[['script_name']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
